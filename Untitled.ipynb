{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ac44b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "import xgcm\n",
    "from xorca.lib import load_xorca_dataset\n",
    "import pickle\n",
    "import eddytools as et\n",
    "from cmocean import cm\n",
    "from dask.diagnostics import ProgressBar\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "from datetime import timedelta\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e8668d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meshpath = ['/scratch/usr/shkifmjr/NUSERDATA/ORION/10-data/meshmask/1_mesh_mask.nc']\n",
    "\n",
    "meshpath_x = ['/scratch/usr/shkmazel/masks/ORION10Xnospongeinocean/1_mesh_mask.nc']\n",
    "\n",
    "datapath = '/scratch/usr/shkifmmp/master/data/ORION10/'\n",
    "datapath_X = '/scratch/usr/shkifmmp/master/data/ORION10X/'\n",
    "\n",
    "path_bathy = '/scratch/usr/shklvn09/SCRATCH/ORION10.L46.LIM2vp.CFCSF6.MOPS.JRA.XIOS2.5.LP01-EXP05/OUT/'\n",
    "path_bathy_x = '/scratch/usr/shkmazel/RESTARTS/ORION10Xnospongeinocean_RESTART/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33b7b04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1997"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1978 + 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aadaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(year, model):\n",
    "    YEAR = str(year)\n",
    "    if model == 'ORION10':\n",
    "        data_in = sorted(glob('/scratch/usr/shkifmmp/master/data/' + model + '/chunked/' +'1_ORION10.L46.LIM2vp.CFCSF6.MOPS.JRA.XIOS2.5.LP01-EXP05_5d_' + YEAR + '0101_' + YEAR + '1231_grid_[TUV].nc'))\n",
    "    \n",
    "    # load data\n",
    "        data = load_xorca_dataset(data_files=data_in, aux_files=meshpath, model_config='NEST',\n",
    "                   input_ds_chunks = {\"time_counter\": 73, \"t\": 73,\n",
    "                                      \"z\": 11, \"deptht\": 11, \"depthu\": 11, \"depthv\": 11, \"depthw\": 11,\n",
    "                                      \"x\": 100, \"y\": 100},\n",
    "                   target_ds_chunks = {\"t\": 73,\n",
    "                                       \"z_c\": 11, \"z_l\": 11,\n",
    "                                       \"x_c\": 100, \"x_r\": 100, \"y_c\": 100, \"y_r\": 100})\n",
    "    \n",
    "    elif model == 'ORION10X':\n",
    "        data_in = sorted(glob('/scratch/usr/shkifmmp/master/data/' + model +  '/chunked/' +'1_FOCI2.0-TM041_5d_' + YEAR + '0101_' + YEAR + '1231_grid_[TUV].nc'))\n",
    "\n",
    "        \n",
    "    # load data\n",
    "        data = load_xorca_dataset(data_files=data_in, aux_files=meshpath_x, model_config='NEST',\n",
    "                   input_ds_chunks = {\"time_counter\": 73, \"t\": 73,\n",
    "                                      \"z\": 11, \"deptht\": 11, \"depthu\": 11, \"depthv\": 11, \"depthw\": 11,\n",
    "                                      \"x\": 100, \"y\": 100},\n",
    "                   target_ds_chunks = {\"t\": 73,\n",
    "                                       \"z_c\": 11, \"z_l\": 11,\n",
    "                                       \"x_c\": 100, \"x_r\": 100, \"y_c\": 100, \"y_r\": 100})\n",
    "\n",
    "    # define metrics for xgcm (not strictly necessary)\n",
    "    at, au = data['e1t'] * data['e2t'], data['e1u'] * data['e2u']\n",
    "    av, af = data['e1v'] * data['e2v'], data['e1f'] * data['e2f']\n",
    "    vt, vu, vv, vw = data['e3t'] * at, data['e3u'] * au, data['e3v'] * av, data['e3w'] * at\n",
    "\n",
    "    data = data.update({'at': at, 'au': au, 'av': av, 'af': af, 'vt': vt, 'vu': vu, 'vv': vv, 'vw': vw})\n",
    "    data = data.set_coords(['at', 'au', 'av', 'af', 'vt', 'vu', 'vv', 'vw'])\n",
    "\n",
    "    metrics = {\n",
    "        ('X',): ['e1t', 'e1u', 'e1v', 'e1f'], # X distances\n",
    "        ('Y',): ['e2t', 'e2u', 'e2v', 'e2f'], # Y distances\n",
    "        ('Z',): ['e3t', 'e3u', 'e3v', 'e3w'], # Z distances\n",
    "        ('X', 'Y'): ['at', 'au', 'av', 'af'], # Areas\n",
    "        ('X', 'Y', 'Z'): ['vt', 'vu', 'vv', 'vw'] # Volumes\n",
    "    }\n",
    "\n",
    "    metrics2D = {\n",
    "        ('X',): ['e1t', 'e1u', 'e1v', 'e1f'], # X distances\n",
    "        ('Y',): ['e2t', 'e2u', 'e2v', 'e2f'], # Y distances\n",
    "        ('X', 'Y'): ['at', 'au', 'av', 'af'], # Areas\n",
    "    }\n",
    "\n",
    "    if model == 'ORION10':\n",
    "        bathy = xr.open_dataset(path_bathy + '1_bathy_meter.nc')\n",
    "        data = data.update({'bathymetry': (['y_c', 'x_c'], bathy['Bathymetry'].data)})\n",
    "    elif model == 'ORION10X':\n",
    "        bathy = xr.open_dataset(path_bathy_x + '1_bathy_meter.nc')\n",
    "        data = data.update({'bathymetry': (['y_c', 'x_c'], bathy['Bathymetry'].data)})\n",
    "        \n",
    "    grid = xgcm.Grid(data, metrics=metrics)\n",
    "\n",
    "    # Calculate vorticity and Okubo-Weiss parameter and make sure the chunk sizes are as before.\n",
    "    data_OW = et.okuboweiss.calc(data.isel(z_c=9, z_l=9), grid,\n",
    "                                 'vozocrtx', 'vomecrty').chunk({'x_c': 1002, 'x_r': 1002,\n",
    "                                                                'y_c': 629, 'y_r': 629})\n",
    "\n",
    "    # Merge the new variables `OW` and `vort` to the dataset `data`\n",
    "    data = xr.merge([data, data_OW], compat='override')\n",
    "\n",
    "    # INTERPOLATION\n",
    "    # Define the parameters for the interpolation -- CONSIDER THE DISOCNTINUITY IN THE LONGITUDE\n",
    "    interpolation_parameters = {'model': 'ORCA',\n",
    "                                'grid': 'latlon',\n",
    "                                'start_time': YEAR + '-01-01', # time range start\n",
    "                                'end_time': YEAR + '-12-31', # time range end\n",
    "                                'calendar': 'standard', # calendar, must be either 360_day or standard\n",
    "                                'lon1': 77.5, # minimum longitude of detection region\n",
    "                                'lon2': 69.5,  # maximum longitude\n",
    "                                'lat1': -65, # minimum latitude\n",
    "                                'lat2': -37, # maximum latitude\n",
    "                                'res': 1./10., # resolution of the fields in degrees\n",
    "                                'vars_to_interpolate': ['OW', 'vort'], # variables to be interpolated \n",
    "                                'mask_to_interpolate': ['fmask', 'tmask', 'bathymetry']} # masks to interpolate\n",
    "\n",
    "    # The OW parameter and vorticity just need to be extracted at the depth level at which we want\n",
    "    # to detect eddies. In this case we chose level 9\n",
    "    data_int_OW = et.interp.horizontal(data.isel(z_c=9, z_l=9), metrics2D, interpolation_parameters)\n",
    "    \n",
    "    #Interpolating heat flux - 2D\n",
    "    interpolation_parameters['vars_to_interpolate'] = ['sohefldo']\n",
    "    interpolation_parameters['mask_to_interpolate'] = ['fmask', 'tmask']\n",
    "\n",
    "    data_int_heat = et.interp.horizontal(data, metrics2D, interpolation_parameters)\n",
    "\n",
    "    # Now we change some of the parameters to interpolate other variables at all depths\n",
    "    # Here we just use temperature and salinity\n",
    "#     interpolation_parameters['vars_to_interpolate'] = ['votemper', 'vosaline']\n",
    "#     interpolation_parameters['mask_to_interpolate'] = ['fmask', 'tmask']\n",
    "\n",
    "    # Now we don't restrict the interpolation to one depth level\n",
    "    data_int = et.interp.horizontal(data, metrics, interpolation_parameters)\n",
    "\n",
    "    # Load `OW` into memory so the `.rolling` operation is faster\n",
    "    OW_tmp = data_int_OW['OW'].compute()\n",
    "\n",
    "     # Convert all land values to `NaN` so we don't have a lot of zeros when calculating\n",
    "    # the standard deviation\n",
    "    OW_tmp = OW_tmp.where(OW_tmp != 0)\n",
    "    lon_tmp = OW_tmp['lon'].where(OW_tmp['lon'] > 0, other=OW_tmp['lon'] + 360.)\n",
    "    OW_tmp = OW_tmp.assign_coords({'lon': lon_tmp})\n",
    "\n",
    "    mean_OW_spatial_std = OW_tmp.rolling(\n",
    "                              lon=100, center=True, min_periods=1\n",
    "                              ).std(skipna=True).rolling(\n",
    "                              lat=100, center=True, min_periods=1\n",
    "                              ).std(skipna=True).mean('time')\n",
    "\n",
    "    # Merge all interpolated datasets into on (override is necessary because some mask etc.\n",
    "    # variables have been written to all datasets)\n",
    "    data_int = xr.merge([data_int, data_int_OW], \n",
    "                       compat='override')#.chunk({'time': 1, 'lat': 100, 'lon': 100})\n",
    "    \n",
    "    data_int = xr.merge([data_int, data_int_heat], \n",
    "                       compat='override').chunk({'time': 1, 'lat': 100, 'lon': 100})\n",
    "\n",
    "    # use if OW_std is 2D\n",
    "#     data_int = data_int.update({'OW_std': (['lat', 'lon'], mean_OW_spatial_std.values)})\n",
    "\n",
    "    data_int = data_int.chunk({'lon': 3561, 'lat': 501, 'z': 46})\n",
    "    with ProgressBar():\n",
    "        data_int.to_netcdf('/scratch/usr/shkifmmp/master/data/' + model + '/interpolated/' + 'int_data_75_71_y' + YEAR + '.nc')\n",
    "        \n",
    "    del data_int, data_int_OW, OW_tmp, data, lon_tmp, data_OW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "366d50d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking(model):\n",
    "    if model == 'ORION10':\n",
    "        data_save = datapath\n",
    "    elif model == 'ORION10X':\n",
    "        data_save = datapath_X\n",
    "    # Specify parameters for eddy tracking\n",
    "    tracking_parameters = {'model': 'ORCA',\n",
    "                           'grid': 'latlon',\n",
    "                           'start_time': '1958-01-03', # time range start\n",
    "                           'end_time': '1977-12-31', # time range end\n",
    "                           'calendar': 'standard', # calendar, must be either 360_day or standard\n",
    "                           'dt': 5, # temporal resolution of the data in days\n",
    "                           'lon1': 77.5, # minimum longitude of detection region\n",
    "                           'lon2': 69.5, # maximum longitudee\n",
    "                           'lat1': -65, # minimum latitude\n",
    "                           'lat2': -37, # maximum latitude\n",
    "                           'dE': 50., # maximum distance of search ellipsis from eddy center in towards the east \n",
    "                                     # (if set to 0, it will be calculated as (150. / (7. / dt)))\n",
    "                           'eddy_scale_min': 0.5, # minimum factor by which eddy amplitude and area are allowed to change in one timestep\n",
    "                           'eddy_scale_max': 1.5, # maximum factor by which eddy amplitude and area are allowed to change in one timestep\n",
    "                           'dict': 0, # dictionary containing detected eddies to be used when not stored in files (set to 0 otherwise)\n",
    "                           'data_path': data_save + 'eddies_detect/acc/', # path to the detected eddies pickle files\n",
    "                           'file_root': 'case9',\n",
    "                           'file_spec': 'eddies_OW0.3_77.5_69.5',\n",
    "                           'ross_path': '/scratch/usr/shkifmmp/master/data/'} # path to rossrad.dat containing Chelton et a1. 1998 Rossby radii\n",
    "    \n",
    "    if 'tracks' in globals():\n",
    "        del globals()['tracks']\n",
    "    \n",
    "    globals()['tracks'] = et.tracking.track(tracking_parameters, in_file=True)\n",
    "    \n",
    "     # We save the tracks for later use\n",
    "    with open(data_save + 'eddies_detect/acc/'\n",
    "              + 'case9_19580101_19771231_tracks_OW0.3_77.5_69.5.pickle', 'wb') as f:\n",
    "        pickle.dump(tracks, f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "    \n",
    "    #return #detection_parameters, tracking_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b912f3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa34022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking at time step  163  of  1460\n",
      "tracking at time step  325  of  1460\n",
      "tracking at time step  488  of  1460\n"
     ]
    }
   ],
   "source": [
    "tracking('ORION10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c77e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_detection(model): #adicionar year_start\n",
    "    \n",
    "    if model == 'ORION10':\n",
    "        data_int = xr.open_mfdataset(sorted(glob(datapath + 'interpolated/' + 'int_data_75*y199[6-9]*') + glob(datapath + 'interpolated/' + 'int_data_75*y2000*')))\n",
    "#         data_int = xr.open_mfdataset(sorted(glob(datapath + 'interpolated/' + 'int_data_75*y201[1-5]*')))\n",
    "\n",
    "    elif model == 'ORION10X':\n",
    "#         data_int = xr.open_mfdataset(sorted(glob(datapath_X + 'interpolated/' + 'int_data_75*y195[8-9]*') + glob(datapath_X + 'interpolated/' + 'int_data_75*y1960*')))\n",
    "        data_int = xr.open_mfdataset(sorted(glob(datapath_X + 'interpolated/' + 'int_data_75*y201[6-7]*')))\n",
    "        \n",
    "    data_int['OW_std'] = data_int.OW_std.mean('time')\n",
    "    data_int['bathymetry'] = data_int.bathymetry.mean('time')\n",
    "    data_int['e1f'] = data_int.e1f.mean('time')\n",
    "    data_int['e2f'] = data_int.e2f.mean('time')\n",
    "    data_int['fmask'] = data_int.fmask.mean('time')\n",
    "    data_int['tmask'] = data_int.tmask.mean('time')\n",
    "    \n",
    "    mask_tmp = xr.open_mfdataset(sorted(glob(datapath + 'interpolated/' + 'int_data_75*y2000*'))).mask_regions\n",
    "    \n",
    "    mask = mask_tmp.copy()\n",
    "    mask = mask.where(mask == 0, other=1)\n",
    "    OW_test = data_int.OW * mask\n",
    "    OW_std_test = data_int.OW_std * mask\n",
    "    vort_test = data_int.vort * mask\n",
    "\n",
    "# data_int = data_int.update({'mask_regions_2': mask})\n",
    "    data_int = data_int.update({'OW_test': OW_test,\n",
    "                               'OW_std_test': OW_std_test,\n",
    "                               'vort_test': vort_test})\n",
    "    return data_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62029b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_int = pre_detection('ORION10X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f442ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_processing(model, time_start): #later add time periods\n",
    "\n",
    "    time_i = str(time_start)\n",
    "    time_e = str(time_start + 1)\n",
    "    factor = 0.3\n",
    "    npix_max = 421\n",
    "    lon1= 77.5\n",
    "    lon2= 69.5\n",
    "\n",
    "\n",
    "    if model == 'ORION10':\n",
    "        data_save = datapath\n",
    "    elif model == 'ORION10X':\n",
    "        data_save = datapath_X\n",
    "    \n",
    "    detection_parameters = {'model': 'ORCA',\n",
    "                        'grid': 'latlon',\n",
    "                        'start_time': time_i + '-01-01', # time range start\n",
    "                        'end_time': time_e + '-12-31', # time range end\n",
    "                        'calendar': 'standard', # calendar, must be either 360_day or standard\n",
    "                        'lon1': lon1, # minimum longitude of detection region\n",
    "                        'lon2': lon2, # maximum longitude\n",
    "                        'lat1': -65, # minimum latitude\n",
    "                        'lat2': -37, # maximum latitude\n",
    "                        'min_dep': 1000, # minimum ocean depth where to look for eddies in m\n",
    "                        'res': 1./10., # resolution of the fields in degree\n",
    "                        'OW_thr': data_int, # \n",
    "                        'OW_thr_name': 'OW_std_test', # Okubo-Weiss threshold for eddy detection\n",
    "                        'OW_thr_factor': -factor, # Okubo-Weiss parameter threshold\n",
    "                        'Npix_min': 10, # minimum number of pixels (grid cells) to be considered as eddy\n",
    "                        'Npix_max': npix_max} # maximum number of pixels (grid cells)\n",
    "    \n",
    "    if 'eddies' in globals():\n",
    "        del globals()['eddies']\n",
    "    \n",
    "    with ProgressBar():\n",
    "        globals()['eddies'] = et.detection.detect_OW(data_int.isel(z=9), detection_parameters, ow_var = 'OW_test', vort_var = 'vort_test')\n",
    "    \n",
    "    # For every time step, we store one file on disk with all the information of the detected\n",
    "    # eddies at this time step\n",
    "    for i in np.arange(0, len(eddies)):\n",
    "        datestring = str(eddies[i][0]['time'])[0:10]\n",
    "        with open(data_save + 'eddies_detect/acc/case9_'\n",
    "              + str(datestring) + '_eddies_OW' + str(factor) + '_' + str(lon1) + '_' + str(lon2) + '.pickle', 'wb') as f:\n",
    "            pickle.dump(eddies[i], f, pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92786f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_processing('ORION10X', 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331b77aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d51b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_processing('ORION10X', 1991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc963ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3_eddy]",
   "language": "python",
   "name": "conda-env-py3_eddy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
